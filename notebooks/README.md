# ğŸ§  RAG Chatbot mit LLMClient (Groq, OpenAI & Hugging Face)

Das Notebook [`RAGChatbot_groq_API.ipynb`](RAGChatbot_groq_API.ipynb) zeigt, wie man mit der Klasse [`LLMClient`](../llm_client/llm_client.py) einen **Retrieval-Augmented-Generation (RAG)**-Chatbot erstellt, der wahlweise Ã¼ber **Groq**, **OpenAI** oder **Ollama** betrieben wird.  

---

## ğŸš€ Inhalt des Notebooks

Das Notebook demonstriert:

1. Installation der benÃ¶tigten Packages in **Google Colab**
2. Nutzung der `LLMClient`-Klasse mit:
   - ğŸ§© **Groq API** *(optional)*
   - ğŸ”® **OpenAI API** *(optional)*
   - ğŸ’» **Ollama (local)** *(Fallback)*
3. Aufbau eines einfachen **RAG-Workflows**:
   - Dokumente laden  
   - Embeddings mit einem Embedding-Modell von **Hugging Face** erzeugen  
   - Antworten aus LLM + Vektorstore kombinieren

---

## ğŸ”‘ Erforderliche API Keys

| Dienst | Pflicht | Zweck |
|--------|----------|--------|
| **Hugging Face API Key** | âœ… **erforderlich** | Laden des Embedding-Modells |
| **Groq API Key** | optional | Nutzung der Groq LLM-API |
| **OpenAI API Key** | optional | Nutzung der OpenAI LLM-API |

Wenn weder Groq- noch OpenAI-Key gesetzt sind, nutzt `LLMClient` automatisch **Ollama** (funktioniert nur lokal und nicht in Google Colab).

---

## ğŸ¦® Hugging Face API Key erstellen

1. Gehe zu [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)  
   <p align="center">
   <img src="images/Hugging%20Face%20-%20settings%20menu%20-%20access%20tokens.png" 
       alt="Hugging Face â€“ Settings Menu" 
       width="250">
   </p>

2. Klicke auf die SchaltflÃ¤che **â€Create new tokenâ€œ**  
   <p align="center">
   <img src="images/Hugging%20Face%20-%20User%20Access%20Tokens.png" 
       alt="Hugging Face â€“ User Access Tokens" 
       width="850">
   </p>

3. Gib einen Namen ein (z. B. `colab-rag`) und wÃ¤hle **Type: Write**  
<p align="center">
   <img src="images/Hugging%20Face%20-%20create%20new%20write%20token.png" 
       alt="Hugging Face â€“ Create New Write Token" 
       width="850">
   </p>

4. Kopiere den angezeigten Token (beginnt meist mit `hf_...`).

---

## âš¡ï¸ Groq API Key erstellen

1. Besuche [https://console.groq.com/keys](https://console.groq.com/keys)  
2. Klicke auf **â€Create API Keyâ€œ**  
   ![Groq API Keys â€“ Create API Key](images/groq%20API%20Keys%20-%20Create%20API%20Key.png)
3. Kopiere den SchlÃ¼ssel (beginnt meist mit `groq_...`).

---

## ğŸ”® OpenAI API Key erstellen

1. Melde dich bei [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys) an  
   <img src="images/OpenAI%20API%20-%20API%20keys.png" 
       alt="OpenAI API â€“ API Keys" 
       width="175">
   </p>

2. Klicke auf **â€Create new secret keyâ€œ**  
   <img src="images/OpenAI%20API%20-%20Create%20new%20secret%20key.png" 
       alt="OpenAI API â€“ Create New Secret Key" 
       width="450">
   </p>

3. Kopiere den Key (beginnt meist mit `sk-...`).

---

## â˜ï¸ API Keys als Secrets in Google Colab hinterlegen

1. Klicke im MenÃ¼ links auf das SchlÃ¼ssel-Symbol ğŸ”‘  
   <img src="images/Google%20Colab%20-%20secrets%20-%20api%20keys.png" 
       alt="Google Colab â€“ Secrets â€“ API Keys" 
       width="600">
   </p>

2. Lege folgende Secrets an:

   | Name | Wert |
   |-------|------|
   | `HF_TOKEN` | dein Hugging Face Token |
   | `GROQ_API_KEY` | (optional) dein Groq API Key |
   | `OPENAI_API_KEY` | (optional) dein OpenAI API Key |

---

## âš™ï¸ Nutzung im Notebook

```python
from llm_client import LLMClient

# LLMClient erkennt automatisch, welche Keys gesetzt sind
client = LLMClient()

print("Verwendete API:", client.api_choice)
print("Modell:", client.llm)
```

Falls kein Groq- oder OpenAI-Key gefunden wird, fÃ¤llt der Client automatisch auf **Ollama** zurÃ¼ck (lokaler Betrieb).

---

## ğŸ§© Lizenz

Dieses Notebook ist Teil des Repositories [**dgaida/llm_client**](https://github.com/dgaida/llm_client).  
Â© 2025 â€“ Daniel Gaida, Technische Hochschule.  
Lizenziert unter der **MIT License**.
